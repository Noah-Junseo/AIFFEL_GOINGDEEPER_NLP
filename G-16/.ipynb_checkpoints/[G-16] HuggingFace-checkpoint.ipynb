{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "taken-assignment",
   "metadata": {},
   "source": [
    "# NLP_GoingDeeper | 16. HuggingFace ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-abuse",
   "metadata": {},
   "source": [
    "NLP frameworkì—ì„œ ê°€ì¥ ëŒ€í‘œì ì¸ Huggingface transformersë¥¼ í™œìš©í•˜ì—¬ ìì‹ ë§Œì˜ ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ì–´ ë³´ë„ë¡ í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ë§Œ, **Huggingface transformersì˜ êµ¬ì¡° ë¶„ì„ë§Œìœ¼ë¡œëŠ” ì‹¤ì œë¡œ í™œìš© ê°€ëŠ¥í•œ ìì‹ ë§Œì˜ ë¬´ê¸°ê°€ ë˜ì§€ ëª»í•©ë‹ˆë‹¤.**\n",
    "\n",
    "ì´ë²ˆ ë…¸ë“œì—ì„œëŠ” ì‹¤ì „ í”„ë¡œì íŠ¸ë¥¼ ê°€ì •í•˜ê³  Huggingface transformers frameworkë¥¼ í™œìš©í•˜ì—¬ ë¹ ë¥´ê²Œ ìì‹ ë§Œì˜ ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ë¥¼ êµ¬ì„±í•´ ë³´ëŠ” ì‹¤ìŠµì„ ì§„í–‰í•˜ê²Œ ë©ë‹ˆë‹¤. framework ë‚´ì˜ Model, Tokenizer, Processor ë“±ì´ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ ê¼¼ê¼¼íˆ ì‚´í´ë³´ê³ , í•˜ë‚˜ì˜ frameworkì— ìµìˆ™í•´ì§„ë‹¤ë©´ ë‹¤ë¥¸ frameworkì— ì ì‘í•˜ëŠ” ê²ƒë„ í›¨ì”¬ ìˆ˜ì›”í•´ì§ˆ ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-extraction",
   "metadata": {},
   "source": [
    "## 1. GLUE Benchmark Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-grove",
   "metadata": {},
   "source": [
    "Pretrained modelì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ ìµœê·¼ì€ SQuAD ë“± ê¸°ì¡´ì— ìœ ëª…í•œ ë°ì´í„°ì…‹ í•œ ê°€ì§€ë§Œ ê°€ì§€ê³  ì„±ëŠ¥ì„ ë…¼í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, classification, summarization, reasoning, Q&A ë“± NLP ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ taskë¥¼ í•´ë‹¹ ëª¨ë¸ í•˜ë‚˜ë§Œì„ ì´ìš©í•´ ëª¨ë‘ ìˆ˜í–‰í•´ ë³´ë©´ì„œ ì¢…í•©ì ì¸ ì„±ëŠ¥ì„ ë…¼í•˜ëŠ” ê²ƒì´ ì¼ë°˜í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ì¤‘ NLP ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ ìµœê·¼ í™œìš©ë˜ëŠ” ëŒ€í‘œì ì¸ ê²ƒ ì¤‘ì— **General Language Understanding Evaluation(GLUE) benchmark Datasetì´ ìˆìŠµë‹ˆë‹¤. ì´ 10ê°€ì§€ ë°ì´í„°ì…‹ì´ ìˆìŠµë‹ˆë‹¤.** ê°ê°ì˜ ê°œìš”ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê´€ë ¨ ë§í¬ëŠ” ì•„ë˜ì— ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì•„ë˜ 10ê°€ì§€ì˜ taskì— ëŒ€í•˜ì—¬ : https://gluebenchmark.com/tasks**\n",
    "\n",
    "**ë¦¬ë”ë³´ë“œ : https://gluebenchmark.com/leaderboard**\n",
    "\n",
    "- CoLA : ë¬¸ë²•ì— ë§ëŠ” ë¬¸ì¥ì¸ì§€ íŒë‹¨\n",
    "- MNLI : ë‘ ë¬¸ì¥ì˜ ê´€ê³„ íŒë‹¨(entailment, contradiction, neutral)\n",
    "- MNLI-MM : ë‘ ë¬¸ì¥ì´ ì•ˆ ë§ëŠ”ì§€ íŒë‹¨\n",
    "- MRPC : ë‘ ë¬¸ì¥ì˜ ìœ ì‚¬ë„ í‰ê°€\n",
    "- SST-2 : ê°ì •ë¶„ì„\n",
    "- STS-B : ë‘ ë¬¸ì¥ì˜ ìœ ì‚¬ë„ í‰ê°€\n",
    "- QQP : ë‘ ì§ˆë¬¸ì˜ ìœ ì‚¬ë„ í‰ê°€\n",
    "- QNLI : ì§ˆë¬¸ê³¼ paragraph ë‚´ í•œ ë¬¸ì¥ì´ í•¨ì˜ ê´€ê³„(entailment)ì¸ì§€ íŒë‹¨\n",
    "- RTE : ë‘ ë¬¸ì¥ì˜ ê´€ê³„ íŒë‹¨(entailment, not_entailment)\n",
    "- WNLI : ì›ë¬¸ì¥ê³¼ ëŒ€ëª…ì‚¬ë¡œ ì¹˜í™˜í•œ ë¬¸ì¥ ì‚¬ì´ì˜ í•¨ì˜ ê´€ê³„ íŒë‹¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-cholesterol",
   "metadata": {},
   "source": [
    "ìµœê·¼ì—ëŠ” í•œ ê°€ì§€ taskì—ë§Œ ìµœì í™”ëœ ëª¨ë¸ì´ ì•„ë‹ˆë¼, **ë‹¤ì–‘í•œ í˜•íƒœì˜ ë¬¸ì œë¥¼ ê³¨ê³ ë£¨ ì˜ í‘¸ëŠ” ëª¨ë¸**ì„ ì°¾ê¸° ìœ„í•œ ë…¸ë ¥ì´ ê³„ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-egypt",
   "metadata": {},
   "source": [
    "## 2. Huggingfaceê°€ ì œê³µí•˜ëŠ” GLUE task ì˜ˆì œ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-classic",
   "metadata": {},
   "source": [
    "**Huggingfaceì™€ ê°™ì€ NLP frameworkëŠ” í•´ë‹¹ frameworkë¥¼ í™œìš©í•˜ì—¬ ìƒˆë¡œ ë§Œë“¤ì–´ì§„ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹ ë¥´ê²Œ í‰ê°€í•´ ë³¼ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì˜ˆì œ ì½”ë“œë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.** ì´ëŸ° ì˜ˆì œ ì½”ë“œê°€ ì—†ë‹¤ë©´ ëª¨ë¸ì„ ìƒˆë¡œ ë§Œë“¤ ë•Œë§ˆë‹¤ ê·¸ ì„±ëŠ¥ì„ ë¹„êµ ì¸¡ì •í•´ ë³´ê¸° ìœ„í•œ ì‘ì—…ì´ ë„ˆë¬´ë‚˜ ë²ˆê±°ë¡­ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ìš°ì„ , Huggingfaceì˜ ì˜ˆì œ ì½”ë“œë¥¼ ë“¤ì—¬ë‹¤ë³´ëŠ” ê²ƒìœ¼ë¡œë¶€í„° ì‹œì‘ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì•„ë˜ ëª…ë ¹ì–´ë¥¼ Cloud Shellì—ì„œ ì…ë ¥í•´ ì„¤ì¹˜ë¥¼ ë°˜ë“œì‹œ ìˆ˜í–‰í•´ì•¼ ì´í›„ì˜ ì§„í–‰ì— ë¬¸ì œê°€ ì—†ìœ¼ë‹ˆ, ê¼­ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤! ğŸ‘**"
   ]
  },
  {
   "attachments": {
    "002.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "herbal-haiti",
   "metadata": {},
   "source": [
    "![002.PNG](attachment:002.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-sewing",
   "metadata": {},
   "source": [
    "ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆë‹¤ë©´ ì•„ë˜ ì½”ë“œë¥¼ í„°ë¯¸ë„ì—ì„œ ìˆ˜í–‰í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "attachments": {
    "003.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "floral-personality",
   "metadata": {},
   "source": [
    "![003.PNG](attachment:003.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-appreciation",
   "metadata": {},
   "source": [
    "ìˆ˜í–‰ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "attachments": {
    "001.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "detailed-network",
   "metadata": {},
   "source": [
    "![001.PNG](attachment:001.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-enterprise",
   "metadata": {},
   "source": [
    "ìœ„ ì½”ë“œëŠ” 10ê°€ì§€ GLUE task ì¤‘ 'mrpc' taskë¥¼ ìˆ˜í–‰í•˜ëŠ” ì˜ˆì œ ì½”ë“œì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì½”ë“œëŠ” **Huggingfaceì˜ framework ê¸°ë°˜ìœ¼ë¡œ BERT bert-base-casedì„ í™œìš©í•˜ì—¬ 'mrpc' taskë¥¼ ìˆ˜í–‰**í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë§Œì•½ task_name ë° ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë¥¼ ì ì ˆíˆ ë³€ê²½í•œ í›„ ìˆ˜í–‰í•˜ë©´ ë‹¤ë¥¸ GLUE taskë„ ê°„ë‹¨íˆ ìˆ˜í–‰í•´ ë³¼ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "modelë„ ë‹¤ì–‘í•˜ê²Œ ë°”ê¾¸ì–´ ë³´ë©´ì„œ ìˆ˜ì›”í•˜ê²Œ ìˆ˜í–‰ ê°€ëŠ¥í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì˜ˆì œë§Œìœ¼ë¡œë„ NLP frameworkì˜ ê°•ë ¥í•¨ì„ ì†ì‰½ê²Œ ëŠê»´ë³¼ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ë§Œ, ìš°ë¦¬ëŠ” NLP frameworkë¥¼ í™œìš©í•´ì„œ ê·¸ì € GLUE taskë§Œ ìˆ˜í–‰í•˜ì§€ëŠ” ì•Šì„ ê²ƒì…ë‹ˆë‹¤. **ì´ frameworkë¥¼ í™œìš©í•˜ì—¬ í•´ê²°í•´ì•¼ í•  ì‹¤ë¬´ í”„ë¡œì íŠ¸ë¥¼ ë¹ ë¥´ê²Œ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë…¸ë“œì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.**\n",
    "\n",
    "ê·¸ëŸ° ìƒí™©ì„ ê°€ì •í•´ì„œ, ë°©ê¸ˆ ìˆ˜í–‰í•´ ë³¸ GLUE 'mrpc' taskë¥¼ ë‚˜ë§Œì˜ ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ë¡œ êµ¬ì„±í•´ì„œ ë‹¤ì‹œ í•´ê²°í•´ ë³´ë„ë¡ í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ Huggingface frameworkì— ëŒ€í•´ ì¢€ ë” ëª…í™•í•˜ê²Œ ì´í•´í•˜ì‹¤ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-plasma",
   "metadata": {},
   "source": [
    "## 3. ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ ì œì‘ : Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-homeless",
   "metadata": {},
   "source": [
    "### mrpc ë°ì´í„°ì…‹ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-winner",
   "metadata": {},
   "source": [
    "ë³¸ê²©ì ìœ¼ë¡œ Huggingface frameworkë¥¼ í™œìš©í•˜ê¸° ìœ„í•´, í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì²« ë‹¨ê³„ì¸ ë°ì´í„° ë¶„ì„ì— ë“¤ì–´ê°‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe9939cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚´ê°€ ì‹œê°„ì„ ì¸¡ì •í•˜ëŠ” ì´ìœ ëŠ” ê° GPUí™˜ê²½ì— ë”°ë¥¸ ëª¨ë¸ ì†ë„ ë¹„êµ.\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tutorial-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, AutoConfig\n",
    "from dataclasses import asdict\n",
    "from transformers.data.processors.utils import DataProcessor, InputExample, InputFeatures\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-capital",
   "metadata": {},
   "source": [
    "GLUE ë°ì´í„°ì…‹ì€ í™ˆí˜ì´ì§€ì—ì„œ ì›ë³¸ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ë„ ìˆì§€ë§Œ, ì´ë²ˆì—ëŠ” **tensorflow_datasetsì—ì„œ ì œê³µ**í•˜ëŠ” ê²ƒì„ ì´ìš©í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜í–‰í•´ ë³´ë©´ 3668ê°œì˜ í›ˆë ¨ ë°ì´í„°ì…‹ì´ ì¡´ì¬í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "happy-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /aiffel/tensorflow_datasets/glue/mrpc/1.0.0\n",
      "INFO:absl:Reusing dataset glue (/aiffel/tensorflow_datasets/glue/mrpc/1.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split None, from /aiffel/tensorflow_datasets/glue/mrpc/1.0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3668"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, info = tfds.load('glue/mrpc', with_info=True)\n",
    "info.splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-basket",
   "metadata": {},
   "source": [
    "**dataëŠ” tf.data.Datasetì„ ìƒì†ë°›ì€ í´ë˜ìŠ¤ì˜ í˜•íƒœ**ê°€ ë  ê²ƒì…ë‹ˆë‹¤. ìš°ì„  1ê°œì˜ ë°ì´í„°ë§Œ ê°€ì ¸ë‹¤ê°€ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ í™•ì¸í•´ ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chicken-forward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: {idx: (), label: (), sentence1: (), sentence2: ()}, types: {idx: tf.int32, label: tf.int64, sentence1: tf.string, sentence2: tf.string}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-inspector",
   "metadata": {},
   "source": [
    "ë°ì´í„°ì…‹ ì•ˆì— ì–´ë–¤ í•­ëª©ì´ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ë‚´ìš©ë„ í•œë²ˆ í™•ì¸í•´ ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unknown-spread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'The identical rovers will act as robotic geologists , searching for evidence of past water .', shape=(), dtype=string)\n",
      "tf.Tensor(b'The rovers act as robotic geologists , moving on six wheels .', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "examples = data['train'].take(1)\n",
    "for example in examples:\n",
    "    sentence1 = example['sentence1']\n",
    "    sentence2 = example['sentence2']\n",
    "    label = example['label']\n",
    "    print(sentence1)\n",
    "    print(sentence2)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-search",
   "metadata": {},
   "source": [
    "### Processorì˜ í™œìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-politics",
   "metadata": {},
   "source": [
    "Huggingface transformersì—ì„œ taskë³„ë¡œ ë°ì´í„°ì…‹ì„ ê°€ê³µí•˜ëŠ” ì¼ë°˜ì ì¸ í´ë˜ìŠ¤ êµ¬ì¡°ì¸ Processorë¥¼ í™œìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ëŠ” ì¶”ìƒ í´ë˜ìŠ¤ì¸ Processorë¥¼ í•œë²ˆ ìƒì†ë°›ì€ í›„, Sequence Classification taskë¥¼ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì˜ Processor ì¶”ìƒ í´ë˜ìŠ¤ì¸ DataProcessorì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "realistic-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"\n",
    "        Gets an example from a dict with tensorflow tensors.\n",
    "\n",
    "        Args:\n",
    "            tensor_dict: Keys and values should match the corresponding Glue\n",
    "                tensorflow_dataset examples.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of :class:`InputExample` for the test set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def tfds_map(self, example):\n",
    "        \"\"\"\n",
    "        Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts\n",
    "        examples to the correct format.\n",
    "        \"\"\"\n",
    "        if len(self.get_labels()) > 1:\n",
    "            example.label = self.get_labels()[int(example.label)]\n",
    "        return example\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-point",
   "metadata": {},
   "source": [
    "ì•„ì§ì€ ì¶”ìƒí´ë˜ìŠ¤ ìƒíƒœì´ê¸° ë•Œë¬¸ì— ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ NotImplementedErrorë¥¼ ë°œìƒì‹œí‚¤ëŠ” ë©”ì†Œë“œë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ë©”ì†Œë“œë“¤ì„ ì˜¤ë²„ë¼ì´ë“œí•´ì•¼ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ í´ë˜ìŠ¤ê°€ ì–»ì–´ì§€ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ëŠ” 'mrpc' ì›ë³¸ ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ì—¬ ëª¨ë¸ì— ì…ë ¥í•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•´ ì£¼ëŠ” **MrpcProcessor í´ë˜ìŠ¤ì…ë‹ˆë‹¤.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "respiratory-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MrpcProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the MRPC data set (GLUE version).\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence1\"].numpy().decode(\"utf-8\"),\n",
    "            tensor_dict[\"sentence2\"].numpy().decode(\"utf-8\"),\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        print(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return [\"0\", \"1\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[3]\n",
    "            text_b = line[4]\n",
    "            label = None if set_type == \"test\" else line[0]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-underground",
   "metadata": {},
   "source": [
    "ì´ê²ƒë§Œìœ¼ë¡œëŠ” í´ë˜ìŠ¤ êµ¬ì¡°ì™€ ë©”ì»¤ë‹ˆì¦˜ì´ ëˆˆì— ì˜ ì•ˆ ë“¤ì–´ì˜¬ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œ ìš°ì„  ì£¼ëª©í•´ì•¼ í•  ë©”ì†Œë“œëŠ” **get_example_from_tensor_dict()** ì…ë‹ˆë‹¤. ì‹¤ì œë¡œ ì´ ë©”ì†Œë“œê°€ ì–´ë–¤ ì—­í• ì„ í•˜ê²Œ ë˜ëŠ”ì§€ ì‚´í´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recognized-accessory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ì›ë³¸ë°ì´í„°------\n",
      "{'idx': <tf.Tensor: shape=(), dtype=int32, numpy=1680>, 'label': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'sentence1': <tf.Tensor: shape=(), dtype=string, numpy=b'The identical rovers will act as robotic geologists , searching for evidence of past water .'>, 'sentence2': <tf.Tensor: shape=(), dtype=string, numpy=b'The rovers act as robotic geologists , moving on six wheels .'>}\n",
      "------processor ê°€ê³µë°ì´í„°------\n",
      "InputExample(guid=1680, text_a='The identical rovers will act as robotic geologists , searching for evidence of past water .', text_b='The rovers act as robotic geologists , moving on six wheels .', label='0')\n"
     ]
    }
   ],
   "source": [
    "processor = MrpcProcessor()\n",
    "examples = data['train'].take(1)\n",
    "\n",
    "for example in examples:\n",
    "    print('------ì›ë³¸ë°ì´í„°------')\n",
    "    print(example)  \n",
    "    example = processor.get_example_from_tensor_dict(example)\n",
    "    print('------processor ê°€ê³µë°ì´í„°------')\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-college",
   "metadata": {},
   "source": [
    "ì›ë³¸ê³¼ ë¹„êµí•´ë³´ë‹ˆ Processorê°€ í•˜ëŠ” ì—­í• ì´ ë¬´ì—‡ì¸ì§€ ì¢€ ë” ëª…í™•í•´ì¡Œì„ì§€ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤. ğŸ˜…\n",
    "\n",
    "í•œë§ˆë””ë¡œ ìš”ì•½í•˜ìë©´ ProcessorëŠ” 'Raw Datasetë¥¼ Annotated Datasetìœ¼ë¡œ ë³€í™˜'í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. í•­ëª©ë³„ë¡œ text_a, text_b, label ë“±ì˜ annotationì´ í¬í•¨ëœ InputExampleë¡œ ë³€í™˜ë˜ì–´ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ì½”ë“œëŠ” **tfds_map()** ë©”ì†Œë“œë¥¼ í™œìš©í•œ ê²½ìš°ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "raising-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputExample(guid=1680, text_a='The identical rovers will act as robotic geologists , searching for evidence of past water .', text_b='The rovers act as robotic geologists , moving on six wheels .', label='0')\n"
     ]
    }
   ],
   "source": [
    "examples = (data['train'].take(1))\n",
    "for example in examples:\n",
    "    example = processor.get_example_from_tensor_dict(example)\n",
    "    example = processor.tfds_map(example)\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-movie",
   "metadata": {},
   "source": [
    "ì´ì „ê³¼ ë³„ë‹¤ë¥¸ ì°¨ì´ëŠ” ì—†ìŠµë‹ˆë‹¤. tfds_mapëŠ” labelì„ ê°€ê³µí•˜ëŠ” ë©”ì†Œë“œì¸ë°, ì´ë¯¸ ìˆ«ìë¡œ ì˜ ê°€ê³µëœ labelì´ê¸° ë•Œë¬¸ì— íŠ¹ë³„í•œ ë³€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì‹¤ì œ labelì„ í™•ì¸í•˜ì—¬ Binary Classification ë¬¸ì œë¡œ ì˜ ì •ì˜ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "actual-cancellation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = processor.get_labels()\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "professional-jersey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0, '1': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-cement",
   "metadata": {},
   "source": [
    "## 4. ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ ì œì‘ : Tokenizer, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-slave",
   "metadata": {},
   "source": [
    "Processorë¥¼ í†µí•´ Frameworkì„ í™œìš©í•˜ì—¬ ë°ì´í„°ì…‹ì„ ê°€ê³µí•˜ëŠ” ì‘ì—…ì„ ì˜ ì§„í–‰í–ˆë‹¤ë©´ ì´ë¯¸ ì ˆë°˜ ì´ìƒ ì§„í–‰í–ˆë‹¤ê³  ë³´ì•„ë„ ë©ë‹ˆë‹¤. NLP ëª¨ë¸ë§ì˜ í•µì‹¬ì„ ì´ë£¨ëŠ” Tokenizerì™€ Modelì€ frameworkì—ì„œ ì´ë¯¸ ì˜ ë§Œë“¤ì–´ì ¸ ìˆëŠ” ê²ƒì„ ì‰½ê²Œ ê°€ì ¸ë‹¤ ì“¸ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ëŸ¼ ì´ì „ ìŠ¤í…ì—ì„œ ë§Œë“  MRPCProcessor í´ë˜ìŠ¤ì™€ frameworkë¥¼ ê²°í•©ì‹œì¼œ ë‚˜ê°€ëŠ” ê³¼ì •ì„ ì§„í–‰í•´ ë³´ê² ìŠµë‹ˆë‹¤. ìš°ì„  ì•„ë˜ì™€ ê°™ì´ tokenizerì™€ modelì„ ê°„ë‹¨íˆ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thermal-armstrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-mouse",
   "metadata": {},
   "source": [
    "ì´ì œ processorì™€ tokenizer, ì›ë³¸ ë°ì´í„°ì…‹ì„ ê²°í•©í•˜ì—¬ modelì— ì…ë ¥í•  ë°ì´í„°ì…‹ì„ ìƒì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bottom-tomato",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def _glue_convert_examples_to_features(examples, tokenizer, max_length, processor, label_list=None, output_mode=\"claasification\") :\n",
    "    if max_length is None :\n",
    "        max_length = tokenizer.max_len\n",
    "    if label_list is None:\n",
    "        label_list = processor.get_labels()\n",
    "        print(\"Using label list %s\" % (label_list))\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "    labels = [label_map[example.label] for example in examples]\n",
    "\n",
    "    batch_encoding = tokenizer(\n",
    "        [(example.text_a, example.text_b) for example in examples],\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(examples)):\n",
    "        inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "\n",
    "        feature = InputFeatures(**inputs, label=labels[i])\n",
    "        features.append(feature)\n",
    "\n",
    "    for i, example in enumerate(examples[:5]):\n",
    "        print(\"*** Example ***\")\n",
    "        print(\"guid: %s\" % (example.guid))\n",
    "        print(\"features: %s\" % features[i])\n",
    "\n",
    "    return features\n",
    "\n",
    "print(\"í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "legendary-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def tf_glue_convert_examples_to_features(examples, tokenizer, max_length, processor, label_list=None, output_mode=\"classification\") :\n",
    "    \"\"\"\n",
    "    :param examples: tf.data.Dataset\n",
    "    :param tokenizer: pretrained tokenizer\n",
    "    :param max_length: exampleì˜ ìµœëŒ€ ê¸¸ì´(ê¸°ë³¸ê°’ : tokenizerì˜ max_len)\n",
    "    :param task: GLUE task ì´ë¦„\n",
    "    :param label_list: ë¼ë²¨ ë¦¬ìŠ¤íŠ¸\n",
    "    :param output_mode: \"regression\" or \"classification\"\n",
    "\n",
    "    :return: taskì— ë§ë„ë¡ featureê°€ êµ¬ì„±ëœ tf.data.Dataset\n",
    "    \"\"\"\n",
    "    examples = [processor.tfds_map(processor.get_example_from_tensor_dict(example)) for example in examples]\n",
    "    features = _glue_convert_examples_to_features(examples, tokenizer, max_length, processor)\n",
    "    label_type = tf.int64\n",
    "\n",
    "    def gen():\n",
    "        for ex in features:\n",
    "            d = {k: v for k, v in asdict(ex).items() if v is not None}\n",
    "            label = d.pop(\"label\")\n",
    "            yield (d, label)\n",
    "\n",
    "    input_names = [\"input_ids\"] + tokenizer.model_input_names\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({k: tf.int32 for k in input_names}, label_type),\n",
    "        ({k: tf.TensorShape([None]) for k in input_names}, tf.TensorShape([])),\n",
    "    )\n",
    "\n",
    "print(\"í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-atlantic",
   "metadata": {},
   "source": [
    "**_glue_convert_examples_to_features()** í•¨ìˆ˜ëŠ” processorê°€ ìƒì„±í•œ exampleì„ tokenizerë¡œ ì¸ì½”ë”©í•˜ì—¬ featureë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì´í›„ **tf_glue_convert_examples_to_features()** í•¨ìˆ˜ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ _glue_convert_examples_to_features()ë¥¼ í˜¸ì¶œí•´ì„œ ì–»ì€ featureë¥¼ ë°”íƒ•ìœ¼ë¡œ tf.data.Datasetì„ ìƒì„±í•˜ì—¬ ë¦¬í„´í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "twelve-taxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label list ['0', '1']\n",
      "*** Example ***\n",
      "guid: 1680\n",
      "features: InputFeatures(input_ids=[101, 1996, 7235, 9819, 2097, 2552, 2004, 20478, 21334, 2015, 1010, 6575, 2005, 3350, 1997, 2627, 2300, 1012, 102, 1996, 9819, 2552, 2004, 20478, 21334, 2015, 1010, 3048, 2006, 2416, 7787, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
      "*** Example ***\n",
      "guid: 1456\n",
      "features: InputFeatures(input_ids=[101, 2625, 2084, 2322, 3867, 1997, 23193, 1005, 1055, 4341, 2052, 2272, 2013, 2437, 13891, 1998, 3259, 2044, 1996, 2436, 17848, 5309, 2003, 2949, 1012, 102, 2625, 2084, 2322, 3867, 1997, 23193, 1005, 1055, 4341, 2052, 2272, 2013, 2437, 13891, 1998, 3259, 2044, 1996, 2436, 17848, 5309, 2003, 3143, 1010, 10262, 2216, 5661, 4995, 1005, 1056, 2853, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
      "*** Example ***\n",
      "guid: 3017\n",
      "features: InputFeatures(input_ids=[101, 6804, 1011, 2158, 14177, 1002, 12457, 1012, 1021, 2454, 1999, 2049, 2834, 2197, 2095, 1998, 2253, 2006, 2000, 5425, 1002, 28203, 1012, 1021, 2454, 1012, 102, 6804, 1011, 2158, 1010, 6758, 18720, 1011, 2410, 1010, 14177, 1002, 12457, 1012, 1021, 2454, 1999, 2049, 2034, 5353, 1998, 2253, 2006, 2000, 2202, 1999, 1002, 28203, 1012, 1021, 2454, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 2896\n",
      "features: InputFeatures(input_ids=[101, 1996, 2526, 2117, 4284, 3463, 2123, 1005, 1056, 2421, 4481, 2013, 2256, 2814, 2012, 4012, 4502, 4160, 1012, 102, 1996, 2095, 1011, 3283, 3616, 2079, 2025, 2421, 4481, 2013, 4012, 4502, 4160, 3274, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 499\n",
      "features: InputFeatures(input_ids=[101, 9168, 1019, 1012, 1019, 2003, 2800, 3322, 1999, 1996, 2142, 2163, 1998, 2710, 1010, 2005, 1037, 3225, 3976, 1997, 2055, 1002, 2260, 1010, 6352, 1012, 102, 9168, 1019, 1012, 1019, 2003, 2085, 2800, 1999, 1996, 1057, 1012, 1055, 1012, 1998, 2710, 2083, 7513, 2449, 7300, 24501, 24038, 2015, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf_glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-sector",
   "metadata": {},
   "source": [
    "tf_glue_convert_examples_to_features() í•¨ìˆ˜ê°€ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì „ë‹¬ë  tf.data.Dataset ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ìœ„ ì½”ë“œëŠ” ê·¸ë ‡ê²Œ ìƒì„±ëœ í•™ìŠµ ë‹¨ê³„ ë°ì´í„°ì…‹ train_datasetì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "suited-mining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
      "array([  101,  1996,  7235,  9819,  2097,  2552,  2004, 20478, 21334,\n",
      "        2015,  1010,  6575,  2005,  3350,  1997,  2627,  2300,  1012,\n",
      "         102,  1996,  9819,  2552,  2004, 20478, 21334,  2015,  1010,\n",
      "        3048,  2006,  2416,  7787,  1012,   102,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>}, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "examples = train_dataset.take(1)\n",
    "for example in examples:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-burden",
   "metadata": {},
   "source": [
    "ê·¸ëŸ¼ ì „ì²´ ë°ì´í„°ì…‹ì„ í¬ê²Œ 3ê°€ì§€ë¡œ ë‚˜ëˆ„ì–´ êµ¬ì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤. **train, validaion, test** ì„¸ ê°€ì§€ë¡œ ë‚˜ëˆ„ì–´ êµ¬ì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "constant-closing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label list ['0', '1']\n",
      "*** Example ***\n",
      "guid: 1680\n",
      "features: InputFeatures(input_ids=[101, 1996, 7235, 9819, 2097, 2552, 2004, 20478, 21334, 2015, 1010, 6575, 2005, 3350, 1997, 2627, 2300, 1012, 102, 1996, 9819, 2552, 2004, 20478, 21334, 2015, 1010, 3048, 2006, 2416, 7787, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
      "*** Example ***\n",
      "guid: 1456\n",
      "features: InputFeatures(input_ids=[101, 2625, 2084, 2322, 3867, 1997, 23193, 1005, 1055, 4341, 2052, 2272, 2013, 2437, 13891, 1998, 3259, 2044, 1996, 2436, 17848, 5309, 2003, 2949, 1012, 102, 2625, 2084, 2322, 3867, 1997, 23193, 1005, 1055, 4341, 2052, 2272, 2013, 2437, 13891, 1998, 3259, 2044, 1996, 2436, 17848, 5309, 2003, 3143, 1010, 10262, 2216, 5661, 4995, 1005, 1056, 2853, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
      "*** Example ***\n",
      "guid: 3017\n",
      "features: InputFeatures(input_ids=[101, 6804, 1011, 2158, 14177, 1002, 12457, 1012, 1021, 2454, 1999, 2049, 2834, 2197, 2095, 1998, 2253, 2006, 2000, 5425, 1002, 28203, 1012, 1021, 2454, 1012, 102, 6804, 1011, 2158, 1010, 6758, 18720, 1011, 2410, 1010, 14177, 1002, 12457, 1012, 1021, 2454, 1999, 2049, 2034, 5353, 1998, 2253, 2006, 2000, 2202, 1999, 1002, 28203, 1012, 1021, 2454, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 2896\n",
      "features: InputFeatures(input_ids=[101, 1996, 2526, 2117, 4284, 3463, 2123, 1005, 1056, 2421, 4481, 2013, 2256, 2814, 2012, 4012, 4502, 4160, 1012, 102, 1996, 2095, 1011, 3283, 3616, 2079, 2025, 2421, 4481, 2013, 4012, 4502, 4160, 3274, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 499\n",
      "features: InputFeatures(input_ids=[101, 9168, 1019, 1012, 1019, 2003, 2800, 3322, 1999, 1996, 2142, 2163, 1998, 2710, 1010, 2005, 1037, 3225, 3976, 1997, 2055, 1002, 2260, 1010, 6352, 1012, 102, 9168, 1019, 1012, 1019, 2003, 2085, 2800, 1999, 1996, 1057, 1012, 1055, 1012, 1998, 2710, 2083, 7513, 2449, 7300, 24501, 24038, 2015, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n"
     ]
    }
   ],
   "source": [
    "# train ë°ì´í„°ì…‹\n",
    "train_dataset = tf_glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, processor=processor)\n",
    "train_dataset_batch = train_dataset.shuffle(100).batch(16).repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "roman-asian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label list ['0', '1']\n",
      "*** Example ***\n",
      "guid: 3155\n",
      "features: InputFeatures(input_ids=[101, 1996, 2265, 1005, 1055, 8503, 5360, 2353, 1011, 4284, 16565, 2566, 3745, 2011, 1037, 10647, 1012, 102, 1996, 2194, 2056, 2023, 19209, 16565, 2011, 1037, 10647, 1037, 3745, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 2472\n",
      "features: InputFeatures(input_ids=[101, 26568, 8040, 12995, 6767, 1010, 4464, 1010, 9601, 1996, 7709, 2012, 1996, 9925, 3016, 2181, 29277, 2073, 2016, 2038, 2042, 2542, 2005, 2195, 2086, 1010, 2056, 2014, 2269, 1010, 3960, 8040, 10606, 21222, 1012, 102, 1996, 7270, 2001, 3718, 9317, 2013, 26568, 8040, 12995, 6767, 1010, 4464, 1010, 2012, 1996, 9925, 3016, 1011, 2181, 29277, 2073, 2016, 2038, 2973, 2005, 2195, 2086, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 3584\n",
      "features: InputFeatures(input_ids=[101, 1996, 2817, 1010, 2405, 6928, 1999, 1996, 3485, 8382, 4167, 2470, 1010, 2003, 3497, 2000, 2036, 6611, 2000, 4286, 1010, 2049, 6048, 2056, 1012, 102, 1996, 2817, 1010, 4146, 2006, 1996, 14332, 1997, 4975, 12328, 1010, 2001, 2108, 2405, 2651, 1999, 1996, 3485, 8382, 4167, 2470, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)\n",
      "*** Example ***\n",
      "guid: 3523\n",
      "features: InputFeatures(input_ids=[101, 2009, 2036, 4107, 1037, 2328, 1011, 1999, 16660, 2094, 5956, 9573, 7170, 2121, 2061, 2008, 2152, 1011, 4304, 16660, 2094, 5956, 3638, 2064, 2022, 2109, 2302, 2383, 2000, 16500, 2019, 3176, 2490, 9090, 1012, 102, 1996, 1055, 2509, 2278, 18827, 12740, 2038, 1037, 2328, 1011, 1999, 16660, 2094, 5956, 9573, 7170, 2121, 1010, 2005, 2742, 1010, 2061, 2008, 2152, 1011, 4304, 16660, 2094, 5956, 3638, 2064, 2022, 5361, 2302, 2019, 3176, 2490, 9090, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 1782\n",
      "features: InputFeatures(input_ids=[101, 2852, 2928, 23680, 20898, 1010, 5655, 1005, 1055, 2155, 3460, 1010, 2056, 2065, 1996, 4319, 2018, 2042, 8564, 3041, 5655, 2052, 2031, 6025, 2062, 1997, 2010, 4167, 4972, 1012, 102, 2852, 2928, 23680, 20898, 1010, 1996, 2155, 1005, 1055, 14246, 1010, 2056, 2018, 1996, 4319, 2042, 8564, 2000, 5655, 3041, 1010, 2002, 2052, 2031, 6025, 2062, 1997, 2010, 4167, 3853, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n"
     ]
    }
   ],
   "source": [
    "# validation ë°ì´í„°ì…‹\n",
    "validation_dataset = tf_glue_convert_examples_to_features(data['validation'], tokenizer, max_length=128, processor=processor)\n",
    "validation_dataset_batch = validation_dataset.shuffle(100).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "moving-omega",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using label list ['0', '1']\n",
      "*** Example ***\n",
      "guid: 163\n",
      "features: InputFeatures(input_ids=[101, 6661, 1999, 8670, 2020, 2091, 1015, 1012, 1019, 3867, 2012, 16923, 7279, 3401, 2011, 16087, 2692, 13938, 2102, 1010, 2125, 1037, 2659, 1997, 17943, 2361, 1010, 1999, 1037, 3621, 6428, 3452, 2414, 3006, 1012, 102, 6661, 1999, 8670, 2020, 2091, 2093, 3867, 2012, 13913, 1011, 1015, 1013, 1018, 7279, 3401, 2011, 5641, 22394, 13938, 2102, 1010, 2125, 1037, 2659, 1997, 17943, 7279, 3401, 1010, 1999, 1037, 6428, 3006, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 131\n",
      "features: InputFeatures(input_ids=[101, 1996, 2148, 4759, 5237, 1998, 13116, 3757, 2036, 2056, 2009, 2052, 5466, 2041, 2030, 4604, 2067, 2035, 3010, 12486, 2747, 1999, 3573, 1012, 102, 1996, 2148, 4759, 5237, 1998, 13116, 3757, 2056, 2009, 2052, 15121, 2030, 2709, 2035, 3010, 12486, 1999, 3573, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 1579\n",
      "features: InputFeatures(input_ids=[101, 1000, 2047, 19095, 2015, 2134, 1005, 1056, 9979, 2122, 3197, 2066, 2027, 2071, 2031, 1010, 1000, 2056, 5487, 4830, 2271, 1010, 3472, 1997, 1996, 3222, 1012, 102, 1000, 2047, 19095, 2015, 2134, 1005, 1056, 9979, 2122, 3197, 2066, 2027, 2071, 2031, 1010, 1000, 5487, 1059, 1012, 4830, 2271, 1010, 1996, 3222, 1005, 1055, 3472, 1010, 2056, 7483, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 1151\n",
      "features: InputFeatures(input_ids=[101, 1000, 1045, 2428, 4669, 2032, 1998, 1045, 2145, 2079, 1010, 1000, 9946, 2632, 2239, 2409, 1996, 9536, 7483, 1012, 102, 1998, 1045, 2428, 4669, 2032, 1010, 1998, 1045, 2145, 2079, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
      "*** Example ***\n",
      "guid: 1021\n",
      "features: InputFeatures(input_ids=[101, 4389, 2865, 7711, 1998, 1996, 6556, 3295, 1997, 1996, 2642, 2352, 2073, 1996, 3554, 3631, 2041, 2081, 2009, 5263, 2000, 12210, 2054, 3047, 1012, 102, 4389, 2865, 7711, 1998, 1996, 6556, 3295, 1997, 1996, 13249, 2081, 2009, 5263, 2000, 12210, 2054, 3047, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n"
     ]
    }
   ],
   "source": [
    "# test ë°ì´í„°ì…‹\n",
    "test_dataset = tf_glue_convert_examples_to_features(data['test'], tokenizer, max_length=128, processor=processor)\n",
    "test_dataset_batch = test_dataset.shuffle(100).batch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-completion",
   "metadata": {},
   "source": [
    "## 5. ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ ì œì‘ : Train/Evaluation, Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-gibson",
   "metadata": {},
   "source": [
    "**ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ì´ ëª¨ë‘ ì¤€ë¹„ëœ ìƒíƒœì„ì„ ê°€ì •**í•œ ìŠ¤í…ì…ë‹ˆë‹¤. ì´í›„ì˜ ê³¼ì •ì€ ì•„ë˜ì™€ ê°™ì´ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-cement",
   "metadata": {},
   "source": [
    "### tf.keras.model ì„ í™œìš©í•œ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-width",
   "metadata": {},
   "source": [
    "ìš°ì„ , ìš°ë¦¬ì—ê²Œ ìµìˆ™í•œ **model.fit()** ì„ ì´ìš©í•œ ëª¨ë¸ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "connected-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(processor.get_labels())\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "complicated-species",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-drunk",
   "metadata": {},
   "source": [
    "í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. ì´ í•™ìŠµì€ ì´ë¯¸ ì˜ í›ˆë ¨ëœ BERT ëª¨ë¸ì„ ê°€ì ¸ë‹¤ê°€ fine-tuningí•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.\n",
    "\n",
    "í¸ì˜ìƒ 2 Epochë§Œ ì§„í–‰í•œ í›„, ê·¸ ì„±ëŠ¥ì„ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "competent-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fadceb588a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fadceb588a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fadceb588a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - ETA: 0s - loss: 0.6047 - acc: 0.6941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 113s 839ms/step - loss: 0.6045 - acc: 0.6942 - val_loss: 0.4972 - val_acc: 0.7868\n",
      "Epoch 2/2\n",
      "115/115 [==============================] - 96s 831ms/step - loss: 0.4673 - acc: 0.7859 - val_loss: 0.3560 - val_acc: 0.8456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fac101c6890>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì´ì „ ìŠ¤í…ì—ì„œ ë°°ì¹˜ì²˜ë¦¬ë¥¼ ì§„í–‰í•œ ë°ì´í„°ì…‹(xxxx_dataset_batch)ì„ í™œìš©\n",
    "model.fit(train_dataset_batch, epochs=2, steps_per_epoch=115, \n",
    "                validation_data=validation_dataset_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-diamond",
   "metadata": {},
   "source": [
    "í•™ìŠµì´ ì˜ ì§„í–‰ë˜ì—ˆë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ í™•ì¸í•´ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "connected-population",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 29s 265ms/step - loss: 0.4946 - acc: 0.7774\n",
      "[0.49460989236831665, 0.7773913145065308]\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_dataset_batch)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "alleged-explorer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì™„ë£Œ!\n",
      "Loss = 0.494610\tAccuracy = 0.777391\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "output_dir = os.getenv('HOME')+'/aiffel/transformers'\n",
    "output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n",
    "\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    for i, v in enumerate(result) :\n",
    "        if i == 0 :\n",
    "            writer.write(\"Loss = %f\\t\" %(v))\n",
    "        if i == 1 :\n",
    "            writer.write(\"Accuracy = %f\\n\" %(v))\n",
    "print(\"ì™„ë£Œ!\")\n",
    "\n",
    "#íŒŒì¼ì— ì“´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸\n",
    "!cat ~/aiffel/transformers/eval_results.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-graham",
   "metadata": {},
   "source": [
    "### TFTrainer ë¥¼ í™œìš©í•œ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-minutes",
   "metadata": {},
   "source": [
    "ì´ë²ˆì—ëŠ” **Huggingfaceì˜ TFTrainerë¥¼ í™œìš©í•´** í•™ìŠµì„ ì§„í–‰í•´ ë´…ì‹œë‹¤.\n",
    "\n",
    "ì´ì „ ë…¸ë“œì—ì„œ ì‚´í´ë³¸ ê²ƒì²˜ëŸ¼ TFTrainerë¥¼ í™œìš©í•˜ê¸° ìœ„í•´ì„œëŠ” TFTrainingArgumentsì— í•™ìŠµ ê´€ë ¨ ì„¤ì •ì„ ë¯¸ë¦¬ ì§€ì •í•´ ë‘ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "included-cutting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# TFTrainerì„ í™œìš©í•˜ëŠ” í˜•íƒœë¡œ ëª¨ë¸ ì¬ìƒì„±\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PreTrainedTokenizer,\n",
    "    TFAutoModelForSequenceClassification,\n",
    "    TFTrainer,\n",
    "    TFTrainingArguments,\n",
    "    glue_compute_metrics,\n",
    "    glue_convert_examples_to_features,\n",
    "    glue_output_modes,\n",
    "    glue_processors,\n",
    "    glue_tasks_num_labels,\n",
    ")\n",
    "\n",
    "output_dir = os.getenv('HOME')+'/aiffel/transformers'\n",
    "\n",
    "training_args = TFTrainingArguments(\n",
    "    output_dir=output_dir,            # outputì´ ì €ì¥ë  ê²½ë¡œ\n",
    "    num_train_epochs=3,              # train ì‹œí‚¬ ì´ epochs\n",
    "    per_device_train_batch_size=16,  # ê° device ë‹¹ batch size\n",
    "    per_device_eval_batch_size=64,   # evaluation ì‹œì— batch size\n",
    "    warmup_steps=500,                # learning rate schedulerì— ë”°ë¥¸ warmup_step ì„¤ì •\n",
    "    weight_decay=0.01,                 # weight decay\n",
    "    logging_dir='./logs',                 # logê°€ ì €ì¥ë  ê²½ë¡œ\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_steps=1000\n",
    ")\n",
    "\n",
    "max_seq_length=128\n",
    "task_name = \"mrpc\"\n",
    "\n",
    "with training_args.strategy.scope():\n",
    "    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-upgrade",
   "metadata": {},
   "source": [
    "ì•„ë˜ì—ì„œ ìƒì„±í•˜ê²Œ ë  TFTrainerì˜ ì¸ìë¡œ ë„˜ê²¨ì£¼ì–´ì•¼ í•  ê²ƒ ì¤‘ì— **compute_metrics** ë©”ì†Œë“œê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ê²ƒì€ taskê°€ classificationì¸ì§€ regressionì¸ì§€ì— ë”°ë¼ ëª¨ë¸ì˜ ì¶œë ¥ í˜•íƒœê°€ ë‹¬ë¼ì§€ë¯€ë¡œ task ë³„ë¡œ ì í•©í•œ ì¶œë ¥ í˜•ì‹ì„ ê³ ë ¤í•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì„ ë¯¸ë¦¬ ì§€ì •í•´ ë‘ëŠ” ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "labeled-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    if output_mode == \"classification\":\n",
    "        preds = np.argmax(p.predictions, axis=1)\n",
    "    elif output_mode == \"regression\":\n",
    "        preds = np.squeeze(p.predictions)\n",
    "    return glue_compute_metrics(task_name, preds, p.label_ids)\n",
    "\n",
    "output_mode = glue_output_modes[task_name]\n",
    "output_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-snake",
   "metadata": {},
   "source": [
    "TFTrainerë¥¼ í™œìš©í•  ë•Œ ë°ì´í„°ì…‹ì—ì„œ ìŠì§€ ì•Šì•„ì•¼ í•  ê²ƒì´ **tf.data.experimental.assert_cardinality() ë¥¼ ë°ì´í„°ì…‹ì— ì ìš©**í•´ ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë¥¼ í˜¸ì¶œí•´ ì£¼ì§€ ì•Šìœ¼ë©´ TFTrainer.train() ì—ì„œ assert failì´ ë°œìƒí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pediatric-aircraft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬´ì‚¬í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.apply(tf.data.experimental.assert_cardinality(info.splits['train'].num_examples))\n",
    "validation_dataset = validation_dataset.apply(tf.data.experimental.assert_cardinality(info.splits['validation'].num_examples))\n",
    "test_dataset = test_dataset.apply(tf.data.experimental.assert_cardinality(info.splits['test'].num_examples))\n",
    "\n",
    "print(\"ë¬´ì‚¬í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-timing",
   "metadata": {},
   "source": [
    "ì´ì œ TFTrainerë¥¼ ìƒì„±í•´ì„œ ë³¸ê²©ì ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "previous-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TFTrainer(\n",
    "    model=model,                           # í•™ìŠµì‹œí‚¬ model\n",
    "    args=training_args,                  # TFTrainingArgumentsì„ í†µí•´ ì„¤ì •í•œ arguments\n",
    "    train_dataset=train_dataset,    # training dataset\n",
    "    eval_dataset=validation_dataset,       # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "renewable-swedish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "if training_args.do_train:\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    tokenizer.save_pretrained(training_args.output_dir)\n",
    "\n",
    "print(\"í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-rugby",
   "metadata": {},
   "source": [
    "í•™ìŠµì´ ëë‚˜ë©´ Evaluationì„ ì§„í–‰í•˜ì—¬ ìœ„ model.fit() ìœ¼ë¡œ í•™ìŠµí•œ ê²½ìš°ì™€ ë¹„êµí•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "broke-glossary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/data/metrics/__init__.py:42: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss = 0.5594404765537807\r\n",
      "eval_acc = 0.822265625\r\n",
      "eval_f1 = 0.8765264586160109\r\n",
      "eval_acc_and_f1 = 0.8493960418080054\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Evaluation\n",
    "results = {}\n",
    "if training_args.do_eval:\n",
    "    result = trainer.evaluate()\n",
    "    output_eval_file = os.path.join(training_args.output_dir, \"eval_results2.txt\")\n",
    "\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        for key, value in result.items():\n",
    "            writer.write(f\"{key} = {value}\\n\")\n",
    "\n",
    "        results.update(result)\n",
    "        \n",
    "#íŒŒì¼ì— ì“´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸\n",
    "!cat ~/aiffel/transformers/eval_results2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "infrared-wireless",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì‘ì—… ì†Œìš” ì‹œê°„ì€ ì•½ 185ì´ˆì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "work_time = round(end_time - start_time)\n",
    "print(f'ì´ ì‘ì—… ì†Œìš” ì‹œê°„ì€ ì•½ {work_time}ì´ˆì…ë‹ˆë‹¤.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d662e752",
   "metadata": {},
   "source": [
    "## 16-6. í”„ë¡œì íŠ¸ : ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ ì§ì ‘ ë§Œë“¤ê¸°\n",
    "ì‹¤ìŠµ ì½”ë“œì—ì„œ ìˆ˜í–‰í•´ ë³¸ ë‚´ìš©ì„ í† ëŒ€ë¡œ, ì´ë²ˆì—ëŠ” GLUE datasetì˜ mnli taskë¥¼ ìˆ˜í–‰í•˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸ í˜•íƒœë¡œ ì§„í–‰í•´ ë´…ì‹œë‹¤.\n",
    "\n",
    "`mnli` taskëŠ” ì´ì „ ìŠ¤í…ì—ì„œ ì‚¬ìš©í•œ BERTë¥¼ ì‚¬ìš©í•˜ë©´ í•™ìŠµì´ ì œëŒ€ë¡œ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. [ì—¬ê¸°](https://huggingface.co/models)ë¥¼ ì°¸ì¡°í•˜ì—¬ BERTê°€ ì•„ë‹Œ ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”. \n",
    "\n",
    "tensorflowì™€ í•´ë‹¹ ëª¨ë¸ì— ëŒ€í•œ taskë¡œ ê²€ìƒ‰í•˜ë©´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ë‚˜ì˜µë‹ˆë‹¤. \n",
    "\n",
    "ê·¸ í›„ ì„ íƒí•œ ëª¨ë¸ì˜ _tokenizer_ì™€ í•´ë‹¹ ëª¨ë¸ì— ëŒ€í•œ task ì™€ ëª¨ë¸ ì˜ ì •ë³´ë¥¼ [ì—¬ê¸°](https://huggingface.co/docs/transformers/index)ì—ì„œ ì°¾ì•„ ì—¬ëŸ¬ë¶„ì˜ í”„ë¡œì íŠ¸ë¥¼ ì™„ì„±í•´ ë³´ì„¸ìš”.\n",
    "\n",
    "ê·¸ëƒ¥ run_glue.pyë¥¼ ëŒë ¤ë³´ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•˜ëŠ” ê²ƒì„ ì›í•˜ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¥¼ ì§€ì¼œì„œ ì§„í–‰í•´ ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1bd483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "1.22.3\n",
      "4.18.0\n",
      "1.1\n"
     ]
    }
   ],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ í™•ì¸í•´ ë´…ë‹ˆë‹¤. ì‚¬ìš©í•  ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ ë‘˜ëŸ¬ë´…ì‹œë‹¤.\n",
    "import tensorflow\n",
    "import numpy\n",
    "import transformers\n",
    "import argparse\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(numpy.__version__)\n",
    "print(transformers.__version__)\n",
    "print(argparse.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed531025",
   "metadata": {},
   "source": [
    "## STEP 1. mnli ë°ì´í„°ì…‹ì„ ë¶„ì„í•´ ë³´ê¸°\n",
    "`tensorflow-datasets`ë¥¼ ì´ìš©í•˜ì—¬ `glue/mnli`ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ë ¤ë©´ `tensorflow-datasets` ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ ì˜¬ë ¤ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "pip install tensorflow-datasets -U\n",
    "\n",
    "ìœ„ ëª…ë ¹ì–´ë¥¼ í†µí•´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—…ê·¸ë ˆì´ë“œë¥¼ ì§„í–‰í•´ ì£¼ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e31ea",
   "metadata": {},
   "source": [
    "## STEP 2. MNLIProcessorí´ë˜ìŠ¤ êµ¬í˜„í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a6b07",
   "metadata": {},
   "source": [
    "## STEP 3. ìœ„ì—ì„œ êµ¬í˜„í•œ processor ë° Huggingfaceì—ì„œ ì œê³µí•˜ëŠ” tokenizerë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„°ì…‹ êµ¬ì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8c983",
   "metadata": {},
   "source": [
    "## STEP 4. modelì„ ìƒì„±í•˜ì—¬ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•´ ë³´ê¸°\n",
    "\n",
    "ğŸ’¡ íŒíŠ¸\n",
    "\n",
    "- í˜¹ì‹œ STEP 2ì˜ ì§„í–‰ì— ì–´ë ¤ì›€ì„ ê²ªê³  ê³„ì‹ ë‹¤ë©´ transformer í”„ë¡œì íŠ¸ ë‚´ë¶€ë¥¼ ì‚´í´ë³´ì‹œë©´ ì°¸ê³ í• ë§Œí•œ ì˜ˆì‹œ ì½”ë“œë¥¼ ì°¾ì•„ë³¼ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. \n",
    "- transformersì˜ ê³µì‹ githubì„ ì°¸ê³ í•˜ëŠ” ê²ƒë„ ì¢‹ì€ ë°©ë²•ì´ì—ìš”!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
